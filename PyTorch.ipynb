{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a1b1f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a35ea376",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('AAPL_Train_Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4ef2e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>IMPACT_SCORE</th>\n",
       "      <th>stock_pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>0.396424</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>0.172300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>0.202093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>0.223581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>-0.288329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>0.461994</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>0.547694</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>0.059643</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>0.301108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           DATE  IMPACT_SCORE  stock_pattern\n",
       "0    2021-01-04      0.396424              0\n",
       "1    2021-01-05      0.172300              0\n",
       "2    2021-01-06      0.202093              1\n",
       "3    2021-01-07      0.223581              1\n",
       "4    2021-01-08     -0.288329              0\n",
       "..          ...           ...            ...\n",
       "251  2022-01-03      0.461994              1\n",
       "252  2022-01-04      0.547694              0\n",
       "253  2022-01-05      0.059643              0\n",
       "254  2022-01-06      0.001395              0\n",
       "255  2022-01-07      0.301108              0\n",
       "\n",
       "[256 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ba07a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = data['IMPACT_SCORE'].to_numpy(), data['stock_pattern'].astype(float).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dedf33ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.806269855, -0.7249699526666666)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.max(), X.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d609c356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 1]), torch.Size([256]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor(X, dtype=torch.float32).reshape(-1, 1)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7e5a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24573536",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassificationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassificationModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(1, 64)\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.layer3 = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb2aab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = BinaryClassificationModel()\n",
    "criterion = nn.BCEWithLogitsLoss() # sigmoid activation function built in\n",
    "# where ```nn.BCELoss() requieres inputs to have gone through the sigmoid activation function\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
    "                           lr=0.1)\n",
    "  # For binary classification\n",
    "optimizer = optim.Adam(model_0.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22e8f343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "    acc = (correct / len(y_pred)) * 100 \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d72ba58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5330],\n",
       "         [0.5436],\n",
       "         [0.5343],\n",
       "         [0.5432],\n",
       "         [0.5347]]),\n",
       " tensor([1., 1., 0., 0., 1.]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    y_logits = model_0(X_test)[:5]\n",
    "y_logits, y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb5d9188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_probs = torch.sigmoid(y_logits)\n",
    "y_prob = torch.round(y_pred_probs.squeeze())\n",
    "accuracy_(y_test[:5], torch.round(y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d14d3b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.7150048017501831\n",
      "Epoch 11/100, Loss: 0.6950927376747131\n",
      "Epoch 21/100, Loss: 0.6918361186981201\n",
      "Epoch 31/100, Loss: 0.692146897315979\n",
      "Epoch 41/100, Loss: 0.6918848752975464\n",
      "Epoch 51/100, Loss: 0.6913567185401917\n",
      "Epoch 61/100, Loss: 0.6910545229911804\n",
      "Epoch 71/100, Loss: 0.6908134818077087\n",
      "Epoch 81/100, Loss: 0.690589427947998\n",
      "Epoch 91/100, Loss: 0.6903620958328247\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model_0.train()\n",
    "    outputs = model_0(X_train).squeeze()\n",
    "    y_pred = torch.round(torch.sigmoid(outputs))\n",
    "    loss = criterion(outputs, y_train)\n",
    "    acc = accuracy_(y_train, y_pred)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f9c454c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.44155844155844"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    test_logits = model_0(X_test).squeeze()\n",
    "    A = (torch.sigmoid(test_logits) > 0.518).float()\n",
    "    test_acc = accuracy_(y_test,\n",
    "                           A)\n",
    "\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95b1e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChurnModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChurnModel, self).__init__()\n",
    "        self.layer_1 = nn.Linear(1, 300, bias=True) \n",
    "        self.layer_2 = nn.Linear(300, 100, bias=True)\n",
    "        self.layer_out = nn.Linear(100, 1, bias=True) \n",
    "        \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid =  nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(p=0.1, inplace=False)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.layer_out(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "738e4430",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = ChurnModel()\n",
    "criterion = nn.BCEWithLogitsLoss() # sigmoid activation function built in\n",
    "# where ```nn.BCELoss() requieres inputs to have gone through the sigmoid activation function\n",
    "  # For binary classification\n",
    "optimizer = optim.Adam(model_1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a6ff98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4819],\n",
       "         [0.4733],\n",
       "         [0.4820],\n",
       "         [0.4734],\n",
       "         [0.4819]]),\n",
       " tensor([1., 1., 0., 0., 1.]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.eval()\n",
    "with torch.inference_mode():\n",
    "    y_logits = model_1(X_test)[:5]\n",
    "y_logits, y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "953835bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_probs = torch.sigmoid(y_logits)\n",
    "y_prob = torch.round(y_pred_probs.squeeze())\n",
    "accuracy_(y_test[:5], torch.round(y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ec30462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.7152904272079468\n",
      "Epoch 11/100, Loss: 0.6980375051498413\n",
      "Epoch 21/100, Loss: 0.6901305913925171\n",
      "Epoch 31/100, Loss: 0.6880898475646973\n",
      "Epoch 41/100, Loss: 0.6831934452056885\n",
      "Epoch 51/100, Loss: 0.6818185448646545\n",
      "Epoch 61/100, Loss: 0.6771154999732971\n",
      "Epoch 71/100, Loss: 0.6773819923400879\n",
      "Epoch 81/100, Loss: 0.6747278571128845\n",
      "Epoch 91/100, Loss: 0.6704778075218201\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model_1.train()\n",
    "    outputs = model_1(X_train).squeeze()\n",
    "    y_pred = torch.round(torch.sigmoid(outputs))\n",
    "    loss = criterion(outputs, y_train)\n",
    "    acc = accuracy_(y_train, y_pred)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b14be42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.44155844155844"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.eval()\n",
    "with torch.inference_mode():\n",
    "    test_logits = model_1(X_test).squeeze()\n",
    "    A = (torch.sigmoid(test_logits) > 0.58).float()\n",
    "    test_acc = accuracy_(y_test,\n",
    "                           A)\n",
    "\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80bb6c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazon\n",
    "\n",
    "data_AMZN = pd.read_csv('AMZN_Train_Test.csv')\n",
    "X,y = data_AMZN['IMPACT_SCORE'].to_numpy(), data_AMZN['stock_pattern'].astype(float).to_numpy()\n",
    "X = torch.tensor(X, dtype=torch.float32).reshape(-1, 1)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "X.shape, y.shape\n",
    "X_train_A, X_test_A, y_train_A, y_test_A = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbb51c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.7518835663795471\n",
      "Epoch 11/100, Loss: 0.7017771601676941\n",
      "Epoch 21/100, Loss: 0.6937776207923889\n",
      "Epoch 31/100, Loss: 0.6932641863822937\n",
      "Epoch 41/100, Loss: 0.6931964755058289\n",
      "Epoch 51/100, Loss: 0.6931796073913574\n",
      "Epoch 61/100, Loss: 0.6931734681129456\n",
      "Epoch 71/100, Loss: 0.6931703686714172\n",
      "Epoch 81/100, Loss: 0.6931684613227844\n",
      "Epoch 91/100, Loss: 0.693166971206665\n"
     ]
    }
   ],
   "source": [
    "model_0_AMZN = BinaryClassificationModel()\n",
    "criterion = nn.BCEWithLogitsLoss() # sigmoid activation function built in\n",
    "optimizer = optim.Adam(model_0_AMZN.parameters(), lr=0.005)\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model_0_AMZN.train()\n",
    "    outputs = model_0_AMZN(X_train_A).squeeze()\n",
    "    y_pred = torch.round(torch.sigmoid(outputs))\n",
    "    loss = criterion(outputs, y_train_A)\n",
    "    acc = accuracy_(y_train_A, y_pred)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcae15b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.56410256410257"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_AMZN.eval()\n",
    "with torch.inference_mode():\n",
    "    test_logits = model_0_AMZN(X_test_A).squeeze()\n",
    "    A = (torch.sigmoid(test_logits) > 0.515).float()\n",
    "    test_acc = accuracy_(y_test_A,\n",
    "                           A)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "194cd963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.7417848706245422\n",
      "Epoch 11/100, Loss: 0.7327902913093567\n",
      "Epoch 21/100, Loss: 0.729496955871582\n",
      "Epoch 31/100, Loss: 0.7236664891242981\n",
      "Epoch 41/100, Loss: 0.7195452451705933\n",
      "Epoch 51/100, Loss: 0.7107111215591431\n",
      "Epoch 61/100, Loss: 0.7038268446922302\n",
      "Epoch 71/100, Loss: 0.7061998844146729\n",
      "Epoch 81/100, Loss: 0.7008187174797058\n",
      "Epoch 91/100, Loss: 0.6970139145851135\n"
     ]
    }
   ],
   "source": [
    "model_1_AMZN = ChurnModel()\n",
    "criterion = nn.BCEWithLogitsLoss() # sigmoid activation function built in\n",
    "# where ```nn.BCELoss() requieres inputs to have gone through the sigmoid activation function\n",
    "  # For binary classification\n",
    "optimizer = optim.Adam(model_1_AMZN.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model_1_AMZN.train()\n",
    "    outputs = model_1_AMZN(X_train_A).squeeze()\n",
    "    y_pred = torch.round(torch.sigmoid(outputs))\n",
    "    loss = criterion(outputs, y_train_A)\n",
    "    acc = accuracy_(y_train_A, y_pred)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd371c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.41025641025641"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_AMZN.eval()\n",
    "with torch.inference_mode():\n",
    "    test_logits = model_1_AMZN(X_test_A).squeeze()\n",
    "    A = (torch.sigmoid(test_logits) > 0.63).float()\n",
    "    test_acc = accuracy_(y_test_A,\n",
    "                           A)\n",
    "\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d18b68f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Microsoft\n",
    "\n",
    "data_MSFT = pd.read_csv('MSFT_Train_Test.csv')\n",
    "X,y = data_MSFT['IMPACT_SCORE'].to_numpy(), data_MSFT['stock_pattern'].astype(float).to_numpy()\n",
    "X = torch.tensor(X, dtype=torch.float32).reshape(-1, 1)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "X.shape, y.shape\n",
    "X_train_M, X_test_M, y_train_M, y_test_M = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "781a18f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.6896273493766785\n",
      "Epoch 11/100, Loss: 0.6812371611595154\n",
      "Epoch 21/100, Loss: 0.6745429039001465\n",
      "Epoch 31/100, Loss: 0.6695445775985718\n",
      "Epoch 41/100, Loss: 0.6665372848510742\n",
      "Epoch 51/100, Loss: 0.6638076305389404\n",
      "Epoch 61/100, Loss: 0.661045491695404\n",
      "Epoch 71/100, Loss: 0.6588720083236694\n",
      "Epoch 81/100, Loss: 0.6574693322181702\n",
      "Epoch 91/100, Loss: 0.6566143035888672\n"
     ]
    }
   ],
   "source": [
    "model_0_MSFT = BinaryClassificationModel()\n",
    "criterion = nn.BCEWithLogitsLoss() # sigmoid activation function built in\n",
    "optimizer = optim.Adam(model_0_MSFT.parameters(), lr=0.005)\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model_0_MSFT.train()\n",
    "    outputs = model_0_MSFT(X_train_M).squeeze()\n",
    "    y_pred = torch.round(torch.sigmoid(outputs))\n",
    "    loss = criterion(outputs, y_train_M)\n",
    "    acc = accuracy_(y_train_M, y_pred)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a02e4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.2089552238806"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_MSFT.eval()\n",
    "with torch.inference_mode():\n",
    "    test_logits = model_0_MSFT(X_test_M).squeeze()\n",
    "    A = (torch.sigmoid(test_logits) > 0.35).float()\n",
    "    test_acc = accuracy_(y_test_M,\n",
    "                           A)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81d873b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.6826261281967163\n",
      "Epoch 11/100, Loss: 0.6631788015365601\n",
      "Epoch 21/100, Loss: 0.6573619842529297\n",
      "Epoch 31/100, Loss: 0.6500556468963623\n",
      "Epoch 41/100, Loss: 0.6480132341384888\n",
      "Epoch 51/100, Loss: 0.6431382894515991\n",
      "Epoch 61/100, Loss: 0.6386541724205017\n",
      "Epoch 71/100, Loss: 0.6331751346588135\n",
      "Epoch 81/100, Loss: 0.6309964656829834\n",
      "Epoch 91/100, Loss: 0.6321460008621216\n"
     ]
    }
   ],
   "source": [
    "model_1_MSFT = ChurnModel()\n",
    "criterion = nn.BCEWithLogitsLoss() # sigmoid activation function built in\n",
    "# where ```nn.BCELoss() requieres inputs to have gone through the sigmoid activation function\n",
    "  # For binary classification\n",
    "optimizer = optim.Adam(model_1_MSFT.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model_1_MSFT.train()\n",
    "    outputs = model_1_MSFT(X_train_M).squeeze()\n",
    "    y_pred = torch.round(torch.sigmoid(outputs))\n",
    "    loss = criterion(outputs, y_train_M)\n",
    "    acc = accuracy_(y_train_M, y_pred)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e959c1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.26865671641791"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_MSFT.eval()\n",
    "with torch.inference_mode():\n",
    "    test_logits = model_1_MSFT(X_test_M).squeeze()\n",
    "    A = (torch.sigmoid(test_logits) > 0.515).float()\n",
    "    test_acc = accuracy_(y_test_M,\n",
    "                           A)\n",
    "\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c8a1e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Microsoft\n",
    "\n",
    "data_NFLX = pd.read_csv('NFLX_Train_Test.csv')\n",
    "X,y = data_NFLX['IMPACT_SCORE'].to_numpy(), data_NFLX['stock_pattern'].astype(float).to_numpy()\n",
    "X = torch.tensor(X, dtype=torch.float32).reshape(-1, 1)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "X.shape, y.shape\n",
    "X_train_N, X_test_N, y_train_N, y_test_N = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb2751f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.6941913366317749\n",
      "Epoch 11/100, Loss: 0.6877966523170471\n",
      "Epoch 21/100, Loss: 0.6870062351226807\n",
      "Epoch 31/100, Loss: 0.6864122748374939\n",
      "Epoch 41/100, Loss: 0.685556173324585\n",
      "Epoch 51/100, Loss: 0.6848663091659546\n",
      "Epoch 61/100, Loss: 0.6843106150627136\n",
      "Epoch 71/100, Loss: 0.6837897896766663\n",
      "Epoch 81/100, Loss: 0.6832754015922546\n",
      "Epoch 91/100, Loss: 0.6827680468559265\n"
     ]
    }
   ],
   "source": [
    "model_0_NFLX = BinaryClassificationModel()\n",
    "criterion = nn.BCEWithLogitsLoss() # sigmoid activation function built in\n",
    "optimizer = optim.Adam(model_0_NFLX.parameters(), lr=0.005)\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model_0_NFLX.train()\n",
    "    outputs = model_0_NFLX(X_train_N).squeeze()\n",
    "    y_pred = torch.round(torch.sigmoid(outputs))\n",
    "    loss = criterion(outputs, y_train_N)\n",
    "    acc = accuracy_(y_train_N, y_pred)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "946d637f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.929577464788736"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_NFLX.eval()\n",
    "with torch.inference_mode():\n",
    "    test_logits = model_0_NFLX(X_test_N).squeeze()\n",
    "    A = (torch.sigmoid(test_logits) > 0.35).float()\n",
    "    test_acc = accuracy_(y_test_N,\n",
    "                           A)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98bab320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.6995649933815002\n",
      "Epoch 11/100, Loss: 0.6867323517799377\n",
      "Epoch 21/100, Loss: 0.6840085983276367\n",
      "Epoch 31/100, Loss: 0.6773212552070618\n",
      "Epoch 41/100, Loss: 0.670452356338501\n",
      "Epoch 51/100, Loss: 0.6670268177986145\n",
      "Epoch 61/100, Loss: 0.6664590835571289\n",
      "Epoch 71/100, Loss: 0.6636513471603394\n",
      "Epoch 81/100, Loss: 0.6620599031448364\n",
      "Epoch 91/100, Loss: 0.6616595983505249\n"
     ]
    }
   ],
   "source": [
    "model_1_NFLX = ChurnModel()\n",
    "criterion = nn.BCEWithLogitsLoss() # sigmoid activation function built in\n",
    "# where ```nn.BCELoss() requieres inputs to have gone through the sigmoid activation function\n",
    "  # For binary classification\n",
    "optimizer = optim.Adam(model_1_NFLX.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model_1_NFLX.train()\n",
    "    outputs = model_1_NFLX(X_train_N).squeeze()\n",
    "    y_pred = torch.round(torch.sigmoid(outputs))\n",
    "    loss = criterion(outputs, y_train_N)\n",
    "    acc = accuracy_(y_train_N, y_pred)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a870e6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.929577464788736"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_NFLX.eval()\n",
    "with torch.inference_mode():\n",
    "    test_logits = model_1_NFLX(X_test_N).squeeze()\n",
    "    A = (torch.sigmoid(test_logits) > 0.555).float()\n",
    "    test_acc = accuracy_(y_test_N,\n",
    "                           A)\n",
    "\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c00db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
